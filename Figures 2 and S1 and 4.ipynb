{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:55:48.503527Z",
     "start_time": "2020-07-14T13:55:44.345544Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\")) \n",
    "import traceback\n",
    "import datetime\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42  # to edit text in Illustrator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patheffects as pe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import warnings\n",
    "\n",
    "from obspy import UTCDateTime, read\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.signal import PPSD\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:55:48.514362Z",
     "start_time": "2020-07-14T13:55:48.507417Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_patch_spines_invisible(ax):\n",
    "    ax.set_frame_on(True)\n",
    "    ax.patch.set_visible(False)\n",
    "    for sp in ax.spines.values():\n",
    "        sp.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:55:48.575246Z",
     "start_time": "2020-07-14T13:55:48.520350Z"
    }
   },
   "outputs": [],
   "source": [
    "timings = pd.read_csv(r\"Supplementary Files/Table S1 - Lockdown stations.csv\", encoding='latin-1', parse_dates=[\"Date_LD1\", \"Date_LD2\"], dayfirst=True,\n",
    "                     index_col=\"Station_Code\")\n",
    "timings = timings.sort_values([\"Date_LD1\", \"Country code\", \"City\"])\n",
    "print(timings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:55:48.598178Z",
     "start_time": "2020-07-14T13:55:48.578195Z"
    }
   },
   "outputs": [],
   "source": [
    "files = sorted(glob(r\"PaperZero_RMS/*Z.csv\"))\n",
    "print(\"There are %i **Z CSV files in the folder\" % len(files))\n",
    "netsta = []\n",
    "seedid = []\n",
    "for f in files:\n",
    "    n,s,l,c,csv = os.path.split(f)[1].split(\".\")\n",
    "    netsta.append(\"%s.%s\" % (n,s))\n",
    "    seedid.append(os.path.split(f)[1].replace(\".csv\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:55:48.606119Z",
     "start_time": "2020-07-14T13:55:48.602130Z"
    }
   },
   "outputs": [],
   "source": [
    "checked_FDSN = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:57:33.495450Z",
     "start_time": "2020-07-14T13:55:48.609109Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sd, ns in zip(seedid, netsta):\n",
    "    _ = timings.filter(like=ns, axis=0)\n",
    "    if not(len(_)):\n",
    "        print(\"%s not found in the timing/time_zone data\" % ns)\n",
    "        continue\n",
    "    if sd in checked_FDSN:\n",
    "        continue\n",
    "    print(ns, sd, \"-->\", _.iloc[0].FDSN)\n",
    "    n,s,l,c = sd.split(\".\")\n",
    "    if n == \"YS\":\n",
    "        continue\n",
    "    try:\n",
    "        client = Client(_.iloc[0].FDSN)\n",
    "        resp = client.get_stations(network=n, station=s, location=l, channel=c, starttime=UTCDateTime(\"2019-12-01\"), level='response')\n",
    "        checked_FDSN[sd] = True\n",
    "        del client\n",
    "    except:\n",
    "        print(\"%s: ERROR cannot access: %s\" % (sd, _.iloc[0].FDSN))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:59:36.760564Z",
     "start_time": "2020-07-14T13:59:08.624318Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "LD1 = []\n",
    "LD2 = []\n",
    "LOC = []\n",
    "labels_left = []\n",
    "labels_right = []\n",
    "country_code = []\n",
    "\n",
    "for seedid, row in timings.iterrows():\n",
    "    code = seedid\n",
    "    if code == \"\":\n",
    "        continue\n",
    "    if code in data:\n",
    "        continue\n",
    "    try:\n",
    "        netsta = \"%s.%s\" % (code.split(\".\")[0], code.split(\".\")[1])\n",
    "    except:\n",
    "        continue\n",
    "    files = glob(r\"PaperZero_RMS/%s.*.*Z.csv\" % netsta)\n",
    "    if not len(files):\n",
    "        continue\n",
    "\n",
    "    file = files[0]\n",
    "    print(\"Processing %s, %s - LD1: %s\" % (code, file, row[\"Date_LD1\"]))\n",
    "    df = pd.read_csv(file, index_col=0, parse_dates=True, dayfirst=True)\n",
    "    if not len(df):\n",
    "        continue\n",
    "    if netsta == \"HE.HEL2\":\n",
    "        # Special case for Helsinki, very high freqs\n",
    "        df = df.loc[:,\"60.0-90.0\"].to_frame()\n",
    "    elif len(df.columns) != 1:\n",
    "        try:\n",
    "            # default case should be 4.0-14.0\n",
    "            df = df.loc[:,\"4.0-14.0\"].to_frame()\n",
    "        except:\n",
    "            # otherwise the last column is taken\n",
    "            df = df.loc[:,df.columns[-2]].to_frame()\n",
    "    \n",
    "    df.columns = [code,]\n",
    "    # Localize the observations to a standard 24h day\n",
    "    try:\n",
    "        df = df.tz_localize(\"UTC\").tz_convert(row[\"TimeZone\"]).tz_localize(None)\n",
    "    except:\n",
    "        try:\n",
    "            df = df.tz_convert(row[\"TimeZone\"]).tz_localize(None)\n",
    "        except:\n",
    "            print(\"ERROR ERRORERRORERRORERROR with %s\" % row[\"TimeZone\"])\n",
    "            traceback.print_exc()\n",
    "            df = df.tz_localize(None)\n",
    "    \n",
    "    # Take the daily median value\n",
    "    df = df.resample(\"1D\").median()\n",
    "    \n",
    "    # Normalize between percentiles 15 and 85 of \"before lockdown\"\n",
    "    if not pd.isnull(row[\"Date_LD1\"]):\n",
    "        preloc = df.loc[:row[\"Date_LD1\"]].copy()\n",
    "        df -= preloc.quantile(0.15)\n",
    "        preloc -= preloc.quantile(0.15)\n",
    "        df /= preloc.quantile(0.85)\n",
    "    else:\n",
    "        df -= df.quantile(0.15)\n",
    "        df /= df.quantile(0.85)\n",
    "    \n",
    "    # Clip the outliers\n",
    "    df = df.clip(None, df.quantile(0.98), axis=1)\n",
    "    data[code] = df\n",
    "    LD1.append(row[\"Date_LD1\"])\n",
    "    LD2.append(row[\"Date_LD2\"])\n",
    "    LOC.append(row[\"City\"])\n",
    "    country_code.append(row[\"Country code\"])\n",
    "    labels_left.append(\"%s - %s\" % (row[\"City\"], row[\"Country code\"]))\n",
    "    labels_right.append(code)\n",
    "    del df\n",
    "print(\"There are %i dataframes loaded\" % len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:59:43.802313Z",
     "start_time": "2020-07-14T13:59:36.763559Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1,1, figsize=(17,24))\n",
    "for i, key in enumerate(data):\n",
    "\n",
    "    df = data[key].copy()\n",
    "    plt.plot(df.index, df -i -.5, c='k', lw=0.8)\n",
    "\n",
    "    try:\n",
    "        plt.plot([LD1[i], LD1[i]],[-i-0.5, -i+0.5], c='r')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        plt.plot([LD2[i], LD2[i]],[-i-0.5, -i+0.5], c='r', ls='--')\n",
    "    except:\n",
    "        pass\n",
    " \n",
    "\n",
    "\n",
    "ax.set_yticks(-np.arange(len(data.keys())), minor=False)\n",
    "ax.set_yticklabels(labels_left, minor=False, ha='right', fontsize=8)\n",
    "ax.get_yaxis().set_tick_params(pad=0)\n",
    "\n",
    "# Hide the right and top spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Only show ticks on the left and bottom spines\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.grid(False)\n",
    "plt.ylim(-i,0)\n",
    "plt.margins(0)\n",
    "\n",
    "plt.xlim(UTCDateTime(\"2019-11-01\").datetime, df.index[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:59:44.266524Z",
     "start_time": "2020-07-14T13:59:43.806266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate all time series in a 2D array for plotting Figure S1 and Figure 2\n",
    "\n",
    "a = pd.concat(data, axis=1)\n",
    "a = a.droplevel(0, axis=1)\n",
    "\n",
    "# Export data for making the video\n",
    "a.loc[\"2019-11-01\":].to_csv(\"FIGURE2_DATA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:59:44.299443Z",
     "start_time": "2020-07-14T13:59:44.270511Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_figure_S1(colormap, show=True, save=False):\n",
    "    matplotlib.rcParams['ytick.labelsize'] = 10.5\n",
    "    matplotlib.rcParams['xtick.labelsize'] = 13\n",
    "    matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "    matplotlib.rcParams['font.sans-serif'] = 'Tahoma' \n",
    "    x = a.index.copy()\n",
    "    y = np.arange(len(labels_left)+1)\n",
    "    fig, ax = plt.subplots(1,1, figsize=(17,24))\n",
    "    plt.pcolormesh(x, y, a.T, vmin=0.00, vmax=1.5, cmap=colormap, antialiased=True, rasterized=True)\n",
    "    plt.colorbar(orientation=\"horizontal\", shrink=0.5, pad=0.02).set_label(\"Normalized Amplitude\", fontsize=12)\n",
    "    for i, L in enumerate(LD1):\n",
    "        if not pd.isnull(L):\n",
    "            plt.scatter(L, i+0.5, marker=\"o\", c='w', )\n",
    "    for i, L in enumerate(LD1):\n",
    "        if not pd.isnull(L):\n",
    "            plt.scatter(L, i+0.5, marker=\"o\", facecolor='w',edgecolor=\"k\", label=\"Lockdown Date\", zorder=-10, s=100)\n",
    "            break\n",
    "    plt.legend(loc=3, fontsize=22, frameon=True, framealpha=1)\n",
    "\n",
    "    plt.yticks(y+0.5, labels_left)\n",
    "    plt.margins(0)\n",
    "    plt.xlim(UTCDateTime(\"2019-12-01\").datetime, UTCDateTime(\"2020-05-05\").datetime)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, axis='y')\n",
    "    ax.set_axisbelow(True)\n",
    "    sns.despine()\n",
    "    ax2 = plt.twinx()\n",
    "    plt.yticks(y+0.5, labels_right)\n",
    "    plt.ylim(ax.get_ylim())\n",
    "    make_patch_spines_invisible(ax2)\n",
    "    ax2.set_axisbelow(True)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.000)\n",
    "    if save:\n",
    "        plt.savefig(r\"FIGURE_S1_%s.png\"%colormap, dpi=300,bbox_inches=\"tight\", pad_inches=0)\n",
    "    if show:\n",
    "        plt.show()\n",
    "        plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:59:58.995665Z",
     "start_time": "2020-07-14T13:59:44.302427Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_figure_S1(\"viridis\", show=True, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:59:59.038546Z",
     "start_time": "2020-07-14T13:59:58.999651Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_figure_2(colormap, show=True, save=False):\n",
    "    matplotlib.rcParams['ytick.labelsize'] = 21\n",
    "    matplotlib.rcParams['xtick.labelsize'] = 20\n",
    "    matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "    matplotlib.rcParams['font.sans-serif'] = 'Tahoma' \n",
    "    \n",
    "    dataset = a.copy()\n",
    "    ix = np.arange(len(dataset.columns))\n",
    "    dataset = dataset.iloc[:,ix]\n",
    "    LL = np.array(labels_left)[ix]\n",
    "    LR = LL[1::2]\n",
    "    LR = [\"%s - %s\" % (L.split(\" - \")[1], L.split(\" - \")[0]) for L in LR]\n",
    "    LL = LL[::2]\n",
    "  \n",
    "\n",
    "    LDS = np.array(LD1)[ix]\n",
    "\n",
    "    \n",
    "    x = dataset.index.copy()\n",
    "    y = np.arange(len(dataset.columns)+1)\n",
    "    \n",
    "    YR = y[1::2]\n",
    "    YL = y[::2]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1, figsize=(17,25))\n",
    "    plt.pcolormesh(x, y, dataset.T, vmin=0.00, vmax=1.5, cmap=colormap, antialiased=True, rasterized=True)\n",
    "    plt.colorbar(orientation=\"horizontal\", shrink=0.5, pad=0.02).set_label(\"Normalized Amplitude\", fontsize=19)\n",
    "    for i, L in enumerate(LDS):\n",
    "        if not pd.isnull(L):\n",
    "            plt.scatter(L, i+0.5, marker=\"o\", c='w', )\n",
    "    for i, L in enumerate(LDS):\n",
    "        if not pd.isnull(L):\n",
    "            plt.scatter(L, i+0.5, marker=\"o\", facecolor='w',edgecolor=\"k\", label=\"Lockdown Date\", zorder=-10, s=100)\n",
    "            break\n",
    "    plt.legend(loc=3, fontsize=22, frameon=True, framealpha=1)\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        plt.plot(x, np.ones(len(x))*i+0.5, lw=0.5, c='silver', zorder=-1)\n",
    "\n",
    "    plt.yticks(YL+0.5, LL)\n",
    "    plt.margins(0)\n",
    "    plt.xlim(UTCDateTime(\"2019-12-01\").datetime, UTCDateTime(\"2020-05-05\").datetime)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    ax.set_axisbelow(True)\n",
    "    sns.despine()\n",
    "    ax2 = plt.twinx()\n",
    "    plt.yticks(YR+0.5, LR)\n",
    "    plt.ylim(ax.get_ylim())\n",
    "    make_patch_spines_invisible(ax2)\n",
    "    ax2.set_axisbelow(True)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.000)\n",
    "    if save:\n",
    "        plt.savefig(r\"FIGURE2.png\"%colormap, dpi=300,bbox_inches=\"tight\", pad_inches=0)\n",
    "    if show:\n",
    "        plt.show()\n",
    "        plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T14:00:11.797780Z",
     "start_time": "2020-07-14T13:59:59.041539Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_figure_2(\"viridis\", show=True, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Mobility vs Seismic Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T14:00:11.815730Z",
     "start_time": "2020-07-14T14:00:11.803762Z"
    }
   },
   "outputs": [],
   "source": [
    "fn = \"Other_Data/Global_Mobility_Report.csv\"\n",
    "if not os.path.isfile(fn):\n",
    "    print(\"We cannot distribute the Google file, please download it and name it %s\" % fn)\n",
    "else:\n",
    "    google = pd.read_csv(fn, parse_dates=True)\n",
    "    google = google.copy().set_index(\"date\")\n",
    "    google = google.groupby([\"country_region_code\", \"date\"],).mean()\n",
    "    google = google.groupby(level=1).median()\n",
    "    google.index = pd.DatetimeIndex(google.index)\n",
    "    google.columns = [c.replace(\"percent_change_from_baseline\",\"\").replace(\"_\", \" \").strip() for c in google.columns]\n",
    "    print(google.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T14:00:11.835685Z",
     "start_time": "2020-07-14T14:00:11.820716Z"
    }
   },
   "outputs": [],
   "source": [
    "fn = \"Other_Data/applemobilitytrends.csv\"\n",
    "if not os.path.isfile(fn):\n",
    "    print(\"We cannot distribute the Apple file, please download it and name it %s\" % fn)\n",
    "else:\n",
    "    apple= pd.read_csv(fn, parse_dates=True)\n",
    "    apple = apple[apple.geo_type == \"country/region\"] #.set_index(\"transportation_type\").T.iloc[3:]\n",
    "    apple = apple.groupby(['transportation_type', 'region']).mean().T\n",
    "    apple = apple.groupby(level=0, axis=1).median()\n",
    "    apple.index = pd.DatetimeIndex(apple.index)\n",
    "    # apple.columns = [\"A: %s\" % s for s in apple.columns]\n",
    "    print(apple.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T14:00:11.861607Z",
     "start_time": "2020-07-14T14:00:11.841661Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_corr_coef(compare):\n",
    "    compare.columns = [\"seismic\", \"other\"]\n",
    "    bins = np.arange(-200,200,10)\n",
    "    ix = pd.cut(compare[\"other\"], bins, retbins=True, labels=False)\n",
    "    compare[\"other\"] = bins[ix[0].astype(int)]\n",
    "    compare = compare.groupby(\"other\").describe()\n",
    "    compare = compare.sort_index()\n",
    "    compare = compare[compare.seismic[\"count\"] >= 3]\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(compare.index,compare.seismic[\"mean\"])\n",
    "    return compare, r_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T14:00:12.489929Z",
     "start_time": "2020-07-14T14:00:11.867591Z"
    }
   },
   "outputs": [],
   "source": [
    "data = ((100*a.loc[\"2019-11-01\":\"2020-05-05\"])-50).median(axis=1)\n",
    "data.index = pd.DatetimeIndex(data.index)\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(11,4), gridspec_kw={\"width_ratios\":(5,2), \"wspace\":0.15})\n",
    "plt.sca(axes[0])\n",
    "plt.plot(data.index, data, label=\"Median of all stations\", c=\"k\", lw=2)\n",
    "\n",
    "for c in mobility.columns:\n",
    "    compare = pd.concat((data, mobility[c], ), axis=1).dropna()\n",
    "    _, r_value = get_corr_coef(compare)\n",
    "    plt.plot(mobility.index, mobility[c], label=\"%s (r= %.2f)\" % (c, r_value), lw=1)\n",
    "\n",
    "\n",
    "plt.ylabel(\"Percent Change\")\n",
    "\n",
    "dr = pd.date_range(\"2019-11-01\", \"2020-05-15\", freq='W-SUN')\n",
    "for d in dr:\n",
    "    plt.axvline(d, c='silver', ls='--', )\n",
    "plt.axvline(d, c='silver', ls='--', label=\"Sundays\")\n",
    "\n",
    "\n",
    "plt.axvline(UTCDateTime(\"2019-12-25\").datetime, c='r', ls='--', label=\"Christmas/New Year\")\n",
    "plt.axvline(UTCDateTime(\"2020-01-01\").datetime, c='r', ls='--')\n",
    "plt.xlabel(\" \")\n",
    "\n",
    "plt.legend(title=\"Seismic Noise & Mobility\", loc=3, ncol=1, fontsize=9)\n",
    "plt.margins(0)\n",
    "plt.xlim(UTCDateTime(\"2019-11-01\").datetime, UTCDateTime(\"2020-05-05\").datetime, )\n",
    "\n",
    "plt.sca(axes[1])\n",
    "axes[1].set_aspect(\"equal\")\n",
    "for c in mobility.columns:\n",
    "    compare = pd.concat((data, mobility[c], ), axis=1).dropna()\n",
    "    compare, r_value = get_corr_coef(compare)\n",
    "    plt.scatter(compare.index, compare.seismic[\"mean\"], label=\"%s (r= %.2f)\" % (c.strip(), r_value))\n",
    "\n",
    "\n",
    "plt.xlim(-80,40)\n",
    "plt.ylim(-80,40)\n",
    "\n",
    "\n",
    "plt.ylabel(\"Seismic Noise Change (%)\")\n",
    "plt.xlabel(\"Mobility Change (%)\")\n",
    "# plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.99, left=0.06, hspace=0.00, wspace=0)\n",
    "# plt.savefig(r\"FIGURE4.png\", dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T05:39:12.650822Z",
     "start_time": "2020-05-19T05:39:09.897702Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
